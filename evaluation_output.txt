2026-01-29 00:45:06.258183: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-01-29 00:45:06.315315: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.

==================================================
EVALUATING BASELINE MODEL
==================================================
Loading base model: Qwen/Qwen2.5-0.5B-Instruct
Loading adapter from: models/baseline
Evaluating 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]/home/biff/.pyenv/versions/3.9.12/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/biff/.pyenv/versions/3.9.12/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
/home/biff/.pyenv/versions/3.9.12/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
  warnings.warn(
  2%|▏         | 1/52 [00:03<02:53,  3.40s/it]  4%|▍         | 2/52 [00:04<01:48,  2.16s/it]  6%|▌         | 3/52 [00:06<01:31,  1.88s/it]  8%|▊         | 4/52 [00:08<01:32,  1.92s/it] 10%|▉         | 5/52 [00:09<01:22,  1.75s/it] 12%|█▏        | 6/52 [00:10<01:10,  1.54s/it] 13%|█▎        | 7/52 [00:11<01:03,  1.41s/it] 15%|█▌        | 8/52 [00:13<01:00,  1.37s/it] 17%|█▋        | 9/52 [00:14<01:00,  1.41s/it] 19%|█▉        | 10/52 [00:15<00:57,  1.36s/it] 21%|██        | 11/52 [00:17<00:55,  1.35s/it] 23%|██▎       | 12/52 [00:18<00:52,  1.32s/it] 25%|██▌       | 13/52 [00:20<00:53,  1.36s/it] 27%|██▋       | 14/52 [00:21<00:50,  1.32s/it] 29%|██▉       | 15/52 [00:22<00:49,  1.33s/it] 31%|███       | 16/52 [00:24<00:49,  1.37s/it] 33%|███▎      | 17/52 [00:25<00:49,  1.40s/it] 35%|███▍      | 18/52 [00:26<00:47,  1.41s/it] 37%|███▋      | 19/52 [00:28<00:47,  1.43s/it] 38%|███▊      | 20/52 [00:29<00:43,  1.35s/it] 40%|████      | 21/52 [00:31<00:45,  1.47s/it] 42%|████▏     | 22/52 [00:33<00:47,  1.58s/it] 44%|████▍     | 23/52 [00:35<00:47,  1.65s/it] 46%|████▌     | 24/52 [00:36<00:44,  1.58s/it] 48%|████▊     | 25/52 [00:38<00:42,  1.59s/it] 50%|█████     | 26/52 [00:39<00:37,  1.46s/it] 52%|█████▏    | 27/52 [00:40<00:35,  1.40s/it] 54%|█████▍    | 28/52 [00:41<00:33,  1.38s/it] 56%|█████▌    | 29/52 [00:43<00:31,  1.39s/it] 58%|█████▊    | 30/52 [00:44<00:31,  1.44s/it] 60%|█████▉    | 31/52 [00:46<00:29,  1.41s/it] 62%|██████▏   | 32/52 [00:47<00:27,  1.40s/it] 63%|██████▎   | 33/52 [00:48<00:26,  1.40s/it] 65%|██████▌   | 34/52 [00:50<00:24,  1.33s/it] 67%|██████▋   | 35/52 [00:51<00:22,  1.30s/it] 69%|██████▉   | 36/52 [00:52<00:21,  1.37s/it] 71%|███████   | 37/52 [00:54<00:19,  1.33s/it] 73%|███████▎  | 38/52 [00:55<00:18,  1.34s/it] 75%|███████▌  | 39/52 [00:56<00:16,  1.25s/it] 77%|███████▋  | 40/52 [00:57<00:15,  1.31s/it] 79%|███████▉  | 41/52 [00:59<00:14,  1.28s/it] 81%|████████  | 42/52 [01:00<00:13,  1.35s/it] 83%|████████▎ | 43/52 [01:02<00:12,  1.39s/it] 85%|████████▍ | 44/52 [01:03<00:11,  1.45s/it] 87%|████████▋ | 45/52 [01:05<00:09,  1.42s/it] 88%|████████▊ | 46/52 [01:06<00:08,  1.44s/it] 90%|█████████ | 47/52 [01:07<00:06,  1.36s/it] 92%|█████████▏| 48/52 [01:08<00:05,  1.33s/it] 94%|█████████▍| 49/52 [01:10<00:03,  1.26s/it] 96%|█████████▌| 50/52 [01:11<00:02,  1.38s/it] 98%|█████████▊| 51/52 [01:13<00:01,  1.37s/it]100%|██████████| 52/52 [01:14<00:00,  1.41s/it]100%|██████████| 52/52 [01:14<00:00,  1.43s/it]
Evaluating faithfulness on 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:02<01:46,  2.08s/it]  4%|▍         | 2/52 [00:04<01:59,  2.40s/it]  6%|▌         | 3/52 [00:08<02:18,  2.83s/it]  8%|▊         | 4/52 [00:10<02:04,  2.58s/it] 10%|▉         | 5/52 [00:12<01:50,  2.34s/it] 12%|█▏        | 6/52 [00:14<01:43,  2.26s/it] 13%|█▎        | 7/52 [00:16<01:40,  2.23s/it] 15%|█▌        | 8/52 [00:18<01:36,  2.18s/it] 17%|█▋        | 9/52 [00:20<01:36,  2.25s/it] 19%|█▉        | 10/52 [00:23<01:37,  2.33s/it] 21%|██        | 11/52 [00:25<01:28,  2.17s/it] 23%|██▎       | 12/52 [00:27<01:23,  2.10s/it] 25%|██▌       | 13/52 [00:29<01:22,  2.12s/it] 27%|██▋       | 14/52 [00:31<01:22,  2.17s/it] 29%|██▉       | 15/52 [00:33<01:20,  2.17s/it] 31%|███       | 16/52 [00:36<01:21,  2.27s/it] 33%|███▎      | 17/52 [00:38<01:16,  2.19s/it] 35%|███▍      | 18/52 [00:40<01:16,  2.24s/it] 37%|███▋      | 19/52 [00:43<01:17,  2.34s/it] 38%|███▊      | 20/52 [00:45<01:15,  2.36s/it] 40%|████      | 21/52 [00:47<01:12,  2.34s/it] 42%|████▏     | 22/52 [00:49<01:07,  2.26s/it] 44%|████▍     | 23/52 [00:52<01:07,  2.33s/it] 46%|████▌     | 24/52 [00:54<01:06,  2.37s/it] 48%|████▊     | 25/52 [00:57<01:04,  2.39s/it] 50%|█████     | 26/52 [00:59<01:00,  2.31s/it] 52%|█████▏    | 27/52 [01:01<00:57,  2.28s/it] 54%|█████▍    | 28/52 [01:04<00:56,  2.35s/it] 56%|█████▌    | 29/52 [01:06<00:51,  2.23s/it] 58%|█████▊    | 30/52 [01:08<00:51,  2.36s/it] 60%|█████▉    | 31/52 [01:11<00:50,  2.38s/it] 62%|██████▏   | 32/52 [01:13<00:48,  2.41s/it] 63%|██████▎   | 33/52 [01:15<00:44,  2.34s/it] 65%|██████▌   | 34/52 [01:18<00:41,  2.30s/it] 67%|██████▋   | 35/52 [01:20<00:37,  2.21s/it] 69%|██████▉   | 36/52 [01:22<00:37,  2.33s/it] 71%|███████   | 37/52 [01:24<00:34,  2.29s/it] 73%|███████▎  | 38/52 [01:27<00:33,  2.41s/it] 75%|███████▌  | 39/52 [01:30<00:31,  2.41s/it] 77%|███████▋  | 40/52 [01:36<00:41,  3.48s/it] 79%|███████▉  | 41/52 [01:38<00:34,  3.16s/it] 81%|████████  | 42/52 [01:40<00:29,  2.92s/it] 83%|████████▎ | 43/52 [01:42<00:23,  2.63s/it] 85%|████████▍ | 44/52 [01:44<00:20,  2.50s/it] 87%|████████▋ | 45/52 [01:47<00:16,  2.42s/it] 88%|████████▊ | 46/52 [01:49<00:14,  2.42s/it] 90%|█████████ | 47/52 [01:51<00:11,  2.34s/it] 92%|█████████▏| 48/52 [01:53<00:08,  2.25s/it] 94%|█████████▍| 49/52 [01:55<00:06,  2.22s/it] 96%|█████████▌| 50/52 [01:59<00:05,  2.71s/it] 98%|█████████▊| 51/52 [02:02<00:02,  2.58s/it]100%|██████████| 52/52 [02:04<00:00,  2.49s/it]100%|██████████| 52/52 [02:04<00:00,  2.39s/it]

==================================================
EVALUATING INTERNAL TOKEN MODEL
==================================================
Loading base model: Qwen/Qwen2.5-0.5B-Instruct
Loading adapter from: models/internal_token
Evaluating 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:00<00:12,  4.22it/s]  4%|▍         | 2/52 [00:00<00:08,  5.79it/s]  6%|▌         | 3/52 [00:00<00:08,  6.10it/s]  8%|▊         | 4/52 [00:00<00:09,  5.15it/s] 10%|▉         | 5/52 [00:00<00:08,  5.58it/s] 12%|█▏        | 6/52 [00:01<00:09,  4.67it/s] 13%|█▎        | 7/52 [00:01<00:08,  5.04it/s] 15%|█▌        | 8/52 [00:01<00:07,  5.64it/s] 17%|█▋        | 9/52 [00:01<00:07,  5.83it/s] 19%|█▉        | 10/52 [00:01<00:06,  6.14it/s] 21%|██        | 11/52 [00:01<00:06,  6.64it/s] 23%|██▎       | 12/52 [00:02<00:07,  5.59it/s] 25%|██▌       | 13/52 [00:02<00:06,  6.11it/s] 27%|██▋       | 14/52 [00:02<00:07,  5.26it/s] 29%|██▉       | 15/52 [00:02<00:07,  4.86it/s] 31%|███       | 16/52 [00:03<00:08,  4.23it/s] 33%|███▎      | 17/52 [00:03<00:07,  4.87it/s] 35%|███▍      | 18/52 [00:03<00:06,  5.16it/s] 37%|███▋      | 19/52 [00:03<00:06,  5.50it/s] 38%|███▊      | 20/52 [00:03<00:06,  4.89it/s] 40%|████      | 21/52 [00:03<00:05,  5.37it/s] 42%|████▏     | 22/52 [00:04<00:06,  4.89it/s] 44%|████▍     | 23/52 [00:04<00:05,  5.43it/s] 46%|████▌     | 24/52 [00:04<00:05,  4.98it/s] 48%|████▊     | 25/52 [00:04<00:04,  5.52it/s] 50%|█████     | 26/52 [00:04<00:04,  6.11it/s] 52%|█████▏    | 27/52 [00:05<00:04,  5.40it/s] 54%|█████▍    | 28/52 [00:05<00:04,  5.02it/s] 56%|█████▌    | 29/52 [00:05<00:04,  5.54it/s] 58%|█████▊    | 30/52 [00:05<00:03,  6.04it/s] 60%|█████▉    | 31/52 [00:05<00:03,  5.34it/s] 62%|██████▏   | 32/52 [00:05<00:03,  5.69it/s] 63%|██████▎   | 33/52 [00:06<00:03,  5.04it/s] 65%|██████▌   | 34/52 [00:06<00:03,  5.54it/s] 67%|██████▋   | 35/52 [00:06<00:03,  4.84it/s] 69%|██████▉   | 36/52 [00:06<00:03,  5.26it/s] 71%|███████   | 37/52 [00:06<00:02,  5.80it/s] 73%|███████▎  | 38/52 [00:07<00:02,  5.23it/s] 75%|███████▌  | 39/52 [00:07<00:02,  5.83it/s] 77%|███████▋  | 40/52 [00:07<00:02,  5.18it/s] 79%|███████▉  | 41/52 [00:07<00:02,  4.52it/s] 81%|████████  | 42/52 [00:08<00:02,  4.09it/s] 83%|████████▎ | 43/52 [00:08<00:02,  4.01it/s] 85%|████████▍ | 44/52 [00:08<00:01,  4.71it/s] 87%|████████▋ | 45/52 [00:08<00:01,  5.38it/s] 88%|████████▊ | 46/52 [00:08<00:01,  4.85it/s] 90%|█████████ | 47/52 [00:09<00:01,  4.13it/s] 92%|█████████▏| 48/52 [00:09<00:01,  3.96it/s] 94%|█████████▍| 49/52 [00:09<00:00,  3.96it/s] 96%|█████████▌| 50/52 [00:09<00:00,  3.94it/s] 98%|█████████▊| 51/52 [00:10<00:00,  4.48it/s]100%|██████████| 52/52 [00:10<00:00,  5.00it/s]100%|██████████| 52/52 [00:10<00:00,  5.07it/s]
Evaluating faithfulness on 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]100%|██████████| 52/52 [00:00<00:00, 991380.95it/s]

==================================================
EVALUATING PARAPHRASE ROBUSTNESS
==================================================
Baseline:
Loading base model: Qwen/Qwen2.5-0.5B-Instruct
Loading adapter from: models/baseline
Evaluating paraphrase robustness on 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:07<06:28,  7.61s/it]  4%|▍         | 2/52 [00:15<06:21,  7.63s/it]  6%|▌         | 3/52 [00:23<06:19,  7.74s/it]  8%|▊         | 4/52 [00:30<06:08,  7.67s/it] 10%|▉         | 5/52 [00:37<05:41,  7.27s/it] 12%|█▏        | 6/52 [00:43<05:19,  6.96s/it] 13%|█▎        | 7/52 [00:50<05:16,  7.02s/it] 15%|█▌        | 8/52 [00:58<05:16,  7.20s/it] 17%|█▋        | 9/52 [01:06<05:22,  7.50s/it] 19%|█▉        | 10/52 [01:12<05:01,  7.19s/it] 21%|██        | 11/52 [01:20<05:05,  7.44s/it] 23%|██▎       | 12/52 [01:27<04:49,  7.23s/it] 25%|██▌       | 13/52 [01:36<04:56,  7.61s/it] 27%|██▋       | 14/52 [01:43<04:41,  7.41s/it] 29%|██▉       | 15/52 [01:50<04:28,  7.27s/it] 31%|███       | 16/52 [01:57<04:19,  7.21s/it] 33%|███▎      | 17/52 [02:04<04:10,  7.16s/it] 35%|███▍      | 18/52 [02:12<04:14,  7.49s/it] 37%|███▋      | 19/52 [02:20<04:15,  7.74s/it] 38%|███▊      | 20/52 [02:27<03:59,  7.49s/it] 40%|████      | 21/52 [02:35<03:51,  7.48s/it] 42%|████▏     | 22/52 [02:43<03:50,  7.67s/it] 44%|████▍     | 23/52 [02:50<03:39,  7.57s/it] 46%|████▌     | 24/52 [02:59<03:40,  7.86s/it] 48%|████▊     | 25/52 [03:07<03:34,  7.94s/it] 50%|█████     | 26/52 [03:13<03:16,  7.55s/it] 52%|█████▏    | 27/52 [03:20<03:02,  7.31s/it] 54%|█████▍    | 28/52 [03:27<02:53,  7.22s/it] 56%|█████▌    | 29/52 [03:35<02:48,  7.35s/it] 58%|█████▊    | 30/52 [03:43<02:48,  7.64s/it] 60%|█████▉    | 31/52 [03:50<02:35,  7.43s/it] 62%|██████▏   | 32/52 [03:57<02:25,  7.27s/it] 63%|██████▎   | 33/52 [04:04<02:16,  7.19s/it] 65%|██████▌   | 34/52 [04:10<02:04,  6.93s/it] 67%|██████▋   | 35/52 [04:17<01:56,  6.85s/it] 69%|██████▉   | 36/52 [04:25<01:55,  7.24s/it] 71%|███████   | 37/52 [04:32<01:47,  7.15s/it] 73%|███████▎  | 38/52 [04:40<01:41,  7.25s/it] 75%|███████▌  | 39/52 [04:47<01:34,  7.25s/it] 77%|███████▋  | 40/52 [04:54<01:25,  7.13s/it] 79%|███████▉  | 41/52 [05:00<01:15,  6.90s/it] 81%|████████  | 42/52 [05:07<01:08,  6.87s/it] 83%|████████▎ | 43/52 [05:14<01:03,  7.08s/it] 85%|████████▍ | 44/52 [05:22<00:56,  7.11s/it] 87%|████████▋ | 45/52 [05:29<00:49,  7.09s/it] 88%|████████▊ | 46/52 [05:36<00:42,  7.14s/it] 90%|█████████ | 47/52 [05:42<00:34,  6.92s/it] 92%|█████████▏| 48/52 [05:49<00:27,  6.84s/it] 94%|█████████▍| 49/52 [05:57<00:21,  7.17s/it] 96%|█████████▌| 50/52 [06:04<00:14,  7.18s/it] 98%|█████████▊| 51/52 [06:11<00:07,  7.01s/it]100%|██████████| 52/52 [06:16<00:00,  6.61s/it]100%|██████████| 52/52 [06:16<00:00,  7.25s/it]
Internal token:
Loading base model: Qwen/Qwen2.5-0.5B-Instruct
Loading adapter from: models/internal_token
Evaluating paraphrase robustness on 52 examples...
  0%|          | 0/52 [00:00<?, ?it/s]  2%|▏         | 1/52 [00:03<03:19,  3.91s/it]  4%|▍         | 2/52 [00:08<03:40,  4.41s/it]  6%|▌         | 3/52 [00:13<03:41,  4.52s/it]  8%|▊         | 4/52 [00:17<03:27,  4.33s/it] 10%|▉         | 5/52 [00:21<03:17,  4.20s/it] 12%|█▏        | 6/52 [00:25<03:05,  4.03s/it] 13%|█▎        | 7/52 [00:29<03:09,  4.22s/it] 15%|█▌        | 8/52 [00:33<03:04,  4.20s/it] 17%|█▋        | 9/52 [00:37<02:47,  3.89s/it] 19%|█▉        | 10/52 [00:41<02:47,  4.00s/it] 21%|██        | 11/52 [00:45<02:50,  4.17s/it] 23%|██▎       | 12/52 [00:50<02:48,  4.21s/it] 25%|██▌       | 13/52 [00:54<02:42,  4.17s/it] 27%|██▋       | 14/52 [00:57<02:27,  3.89s/it] 29%|██▉       | 15/52 [01:00<02:17,  3.72s/it] 31%|███       | 16/52 [01:06<02:33,  4.27s/it] 33%|███▎      | 17/52 [01:10<02:27,  4.21s/it] 35%|███▍      | 18/52 [01:15<02:33,  4.50s/it] 37%|███▋      | 19/52 [01:19<02:25,  4.42s/it] 38%|███▊      | 20/52 [01:24<02:22,  4.46s/it] 40%|████      | 21/52 [01:28<02:14,  4.33s/it] 42%|████▏     | 22/52 [01:32<02:10,  4.34s/it] 44%|████▍     | 23/52 [01:36<02:01,  4.20s/it] 46%|████▌     | 24/52 [01:42<02:12,  4.75s/it] 48%|████▊     | 25/52 [01:47<02:10,  4.84s/it] 50%|█████     | 26/52 [01:51<01:56,  4.48s/it] 52%|█████▏    | 27/52 [01:56<01:57,  4.69s/it] 54%|█████▍    | 28/52 [02:00<01:49,  4.58s/it] 56%|█████▌    | 29/52 [02:04<01:42,  4.44s/it] 58%|█████▊    | 30/52 [02:08<01:34,  4.31s/it] 60%|█████▉    | 31/52 [02:13<01:31,  4.34s/it] 62%|██████▏   | 32/52 [02:17<01:27,  4.35s/it] 63%|██████▎   | 33/52 [02:22<01:25,  4.48s/it] 65%|██████▌   | 34/52 [02:26<01:16,  4.24s/it] 67%|██████▋   | 35/52 [02:30<01:13,  4.33s/it] 69%|██████▉   | 36/52 [02:35<01:12,  4.54s/it] 71%|███████   | 37/52 [02:40<01:11,  4.73s/it] 73%|███████▎  | 38/52 [02:44<01:03,  4.50s/it] 75%|███████▌  | 39/52 [02:48<00:56,  4.32s/it] 77%|███████▋  | 40/52 [02:53<00:52,  4.38s/it] 79%|███████▉  | 41/52 [02:57<00:48,  4.42s/it] 81%|████████  | 42/52 [03:01<00:42,  4.27s/it] 83%|████████▎ | 43/52 [03:06<00:39,  4.40s/it] 85%|████████▍ | 44/52 [03:10<00:35,  4.40s/it] 87%|████████▋ | 45/52 [03:15<00:30,  4.32s/it] 88%|████████▊ | 46/52 [03:19<00:25,  4.29s/it] 90%|█████████ | 47/52 [03:22<00:20,  4.04s/it] 92%|█████████▏| 48/52 [03:27<00:16,  4.17s/it] 94%|█████████▍| 49/52 [03:32<00:14,  4.67s/it] 96%|█████████▌| 50/52 [03:37<00:09,  4.72s/it] 98%|█████████▊| 51/52 [03:42<00:04,  4.77s/it]100%|██████████| 52/52 [03:45<00:00,  4.07s/it]100%|██████████| 52/52 [03:45<00:00,  4.33s/it]

==================================================
COMPARISON SUMMARY
==================================================

Metric                                     Baseline  Internal Token           Delta
--------------------------------------------------------------------------------
accuracy                                      0.769           0.942          +0.173
avg_visible_tokens                           41.750           4.442         -37.308
faithfulness_score                            0.788           1.000          +0.212
paraphrase_consistency                        0.827           0.942          +0.115

token_usage_rate                                N/A           0.000
token_accuracy                                  N/A           0.500

Results saved to evaluation_results.json
